{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_csv_results(IMAGE_FOLDER, OUTPUT_FOLDER, action_idx):\n",
    "    print(IMAGE_FOLDER)\n",
    "    OUTPUT = [] # Used to save the hand key information of all pictures in the entire current folder\n",
    "    CSV_FILE = os.path.join(OUTPUT_FOLDER, f\"{action_idx}.csv\")\n",
    "    IMAGE_FILES = os.listdir(IMAGE_FOLDER)\n",
    "    with mp_hands.Hands(\n",
    "        static_image_mode=True,\n",
    "        max_num_hands=2,\n",
    "        min_detection_confidence=0.5) as hands:\n",
    "        for idx, file in enumerate(IMAGE_FILES):\n",
    "            image_file = os.path.join(IMAGE_FOLDER, file)\n",
    "            image = cv2.flip(cv2.imread(image_file), 1)\n",
    "            results = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "            if not results.multi_handedness: # If the hand cannot be detected, skip it\n",
    "                continue\n",
    "\n",
    "            Left, Right = False, False  # Used to distinguish between left and right hands\n",
    "\n",
    "            num_hands = len(results.multi_handedness)\n",
    "            if num_hands == 2:\n",
    "                Left, Right = True, True\n",
    "            elif num_hands == 1:\n",
    "                if results.multi_handedness[0].classification[0].label == \"Left\":\n",
    "                    Left = True\n",
    "                else:\n",
    "                    Right = True\n",
    "\n",
    "            output = {}\n",
    "            output['Left'] = []\n",
    "            output['Right'] = []\n",
    "            for idx, hand_landmarks in enumerate(results.multi_hand_landmarks):\n",
    "                if Left and idx == 0:\n",
    "                    for data in hand_landmarks.landmark:\n",
    "                        output[\"Left\"] += [data.x, data.y, data.z]\n",
    "                else:\n",
    "                    for data in hand_landmarks.landmark:\n",
    "                        output[\"Right\"] += [data.x, data.y, data.z]\n",
    "            OUTPUT.append(output)\n",
    "    df = pd.DataFrame(OUTPUT)\n",
    "    df.to_csv(CSV_FILE)"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T06:22:34.025712Z",
     "start_time": "2025-01-25T02:48:18.769602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "# Define folder name mapping\n",
    "folder_name_mapping = {\n",
    "    \"Step_1\": \"1\",\n",
    "    \"Step_2_Left\": \"2lt\",\n",
    "    \"Step_2_Right\": \"2rt\",\n",
    "    \"Step_3\": \"3\",\n",
    "    \"Step_4_Left\": \"4lt\",\n",
    "    \"Step_4_Right\": \"4rt\",\n",
    "    \"Step_5_Left\": \"5lt\",\n",
    "    \"Step_5_Right\": \"5rt\",\n",
    "    \"Step_6_Left\": \"6lt\",\n",
    "    \"Step_6_Right\": \"6rt\",\n",
    "    \"Step_7_Left\": \"7lt\",\n",
    "    \"Step_7_Right\": \"7rt\",\n",
    "}\n",
    "\n",
    "def get_frame(file_path, save_folder):\n",
    "    \"\"\"Extract frames from a video file and save them as images.\"\"\"\n",
    "    video = cv2.VideoCapture(file_path)\n",
    "    count = 0\n",
    "    while True:\n",
    "        success, frame = video.read()\n",
    "        if not success:\n",
    "            break\n",
    "        save_path = os.path.join(save_folder, f'{count}.jpg')\n",
    "        cv2.imwrite(save_path, frame)\n",
    "        count += 1\n",
    "    video.release()\n",
    "\n",
    "def process_videos(dataset_path, output_path):\n",
    "    \"\"\"Process all .mp4 videos in dataset_path and save images in output_path.\"\"\"\n",
    "    for root, dirs, files in os.walk(dataset_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.mp4'):  # Process only .mp4 files\n",
    "                # Get the relative path of the folder\n",
    "                relative_path = os.path.relpath(root, dataset_path)\n",
    "\n",
    "                # Map the folder name to the new name\n",
    "                folder_name = os.path.basename(relative_path)\n",
    "                mapped_folder_name = folder_name_mapping.get(folder_name, folder_name)\n",
    "\n",
    "                # Create the corresponding output folder\n",
    "                save_folder = os.path.join(output_path, mapped_folder_name)\n",
    "                os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "                # Get the full video file path\n",
    "                file_path = os.path.join(root, file)\n",
    "\n",
    "                # Extract frames and save them\n",
    "                get_frame(file_path, save_folder)\n",
    "\n",
    "                # Break after processing the first file\n",
    "                #break\n",
    "\n",
    "# Define paths\n",
    "dataset_path = 'data/HandWashDataset'  # Path to the dataset folder\n",
    "output_path = 'data/image'  # Path to the output folder\n",
    "\n",
    "# Process videos\n",
    "process_videos(dataset_path, output_path)\n"
   ],
   "id": "6795a86873fbb64c",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T15:00:34.137707Z",
     "start_time": "2025-01-25T14:52:01.853922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "\n",
    "# Define the CSV generation function\n",
    "def get_csv_results(IMAGE_FOLDER, OUTPUT_FOLDER, action_idx):\n",
    "    print(f\"Processing: {IMAGE_FOLDER}\")\n",
    "    OUTPUT = []  # Used to save the hand key information of all pictures in the current folder\n",
    "    CSV_FILE = os.path.join(OUTPUT_FOLDER, f\"{action_idx}.csv\")\n",
    "    IMAGE_FILES = sorted(os.listdir(IMAGE_FOLDER))  # Ensure sorted processing\n",
    "    with mp.solutions.hands.Hands(\n",
    "        static_image_mode=True,\n",
    "        max_num_hands=2,\n",
    "        min_detection_confidence=0.5) as hands:\n",
    "        for idx, file in enumerate(IMAGE_FILES):\n",
    "            image_file = os.path.join(IMAGE_FOLDER, file)\n",
    "            #image = cv2.imread(image_file)\n",
    "            image = cv2.flip(cv2.imread(image_file), 1) # 1:Rt&Lt 0:UP&Down -1:all\n",
    "            results = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "            if not results.multi_handedness:  # If the hand cannot be detected, skip it\n",
    "                continue\n",
    "\n",
    "            Left, Right = False, False  # Used to distinguish between left and right hands\n",
    "\n",
    "            num_hands = len(results.multi_handedness)\n",
    "            if num_hands == 2:\n",
    "                Left, Right = True, True\n",
    "            elif num_hands == 1:\n",
    "                if results.multi_handedness[0].classification[0].label == \"Left\":\n",
    "                    Left = True\n",
    "                else:\n",
    "                    Right = True\n",
    "\n",
    "            output = {}\n",
    "            output['Left'] = []\n",
    "            output['Right'] = []\n",
    "            for idx, hand_landmarks in enumerate(results.multi_hand_landmarks):\n",
    "                if Left and idx == 0:\n",
    "                    for data in hand_landmarks.landmark:\n",
    "                        output[\"Left\"] += [data.x, data.y, data.z]\n",
    "                else:\n",
    "                    for data in hand_landmarks.landmark:\n",
    "                        output[\"Right\"] += [data.x, data.y, data.z]\n",
    "            OUTPUT.append(output)\n",
    "    df = pd.DataFrame(OUTPUT)\n",
    "    os.makedirs(OUTPUT_FOLDER, exist_ok=True)  # Ensure the output folder exists\n",
    "    df.to_csv(CSV_FILE, index=False)\n",
    "\n",
    "# Define paths\n",
    "image_folder = 'data/image'  # Path to the folder containing extracted images\n",
    "output_folder = 'data/landmark'  # Path to save the CSV files\n",
    "\n",
    "# Generate CSVs for each folder in the /image directory\n",
    "for folder_name in os.listdir(image_folder):\n",
    "    folder_path = os.path.join(image_folder, folder_name)\n",
    "    if os.path.isdir(folder_path):  # Ensure it's a directory\n",
    "        get_csv_results(folder_path, output_folder, folder_name)\n"
   ],
   "id": "3e0a2ef8efc4a7ce",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-25 14:52:02.453081: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-25 14:52:02.494601: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-25 14:52:02.496851: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-25 14:52:03.297867: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: data/image/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1737816724.176555   28568 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1737816724.187486   28665 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-130-generic, LLVM 12.0.0)\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: data/image/2lt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1737816768.456721   28568 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1737816768.458853   28717 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-130-generic, LLVM 12.0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: data/image/2rt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1737816805.497822   28568 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1737816805.499092   28861 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-130-generic, LLVM 12.0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: data/image/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1737816844.391002   28568 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1737816844.393065   29226 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-130-generic, LLVM 12.0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: data/image/4lt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1737816881.733536   28568 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1737816881.734793   29259 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-130-generic, LLVM 12.0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: data/image/4rt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1737816934.871325   28568 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1737816934.873417   29536 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-130-generic, LLVM 12.0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: data/image/5lt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1737816976.758594   28568 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1737816976.759846   29714 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-130-generic, LLVM 12.0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: data/image/5rt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1737817029.410886   28568 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1737817029.412179   29753 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-130-generic, LLVM 12.0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: data/image/6lt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1737817074.348525   28568 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1737817074.350565   29785 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-130-generic, LLVM 12.0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: data/image/6rt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1737817123.469039   28568 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1737817123.470943   29818 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-130-generic, LLVM 12.0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: data/image/7lt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1737817161.669080   28568 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1737817161.670287   29845 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-130-generic, LLVM 12.0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: data/image/7rt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1737817198.929812   28568 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1737817198.931054   29874 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-130-generic, LLVM 12.0.0)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8880b18931e244d2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
